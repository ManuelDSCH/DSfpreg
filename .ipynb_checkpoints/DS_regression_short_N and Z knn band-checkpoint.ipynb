{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4er_OJvVpEq1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ovKinWykpEq2"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_los.csv\")\n",
    "test = pd.read_csv(\"test_los.csv\")\n",
    "submission_csv = pd.read_csv(\"sample_sol_los.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_diagnoses = pd.read_csv(\"extra_diagnoses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55440, 28424, 86233, ...,  9725, 22337, 94290], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra = extra_diagnoses.copy()\n",
    "unique = data[\"subject_id\"].unique()\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10959/10959 [01:01<00:00, 178.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dicto = {}\n",
    "for n in tqdm(unique):\n",
    "    dicto.update({n: len(extra.query(\"SUBJECT_ID == {}\".format(n))[\"HADM_ID\"].unique())})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13025/13025 [01:14<00:00, 174.67it/s]\n"
     ]
    }
   ],
   "source": [
    "unique = data[\"hadm_id\"].unique()\n",
    "dicto2 = {}\n",
    "for n in tqdm(unique):\n",
    "    dicto2.update({n: len(extra.query(\"HADM_ID == {}\".format(n))[\"ICD9_CODE\"].unique())})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13025/13025 [01:15<00:00, 172.09it/s]\n"
     ]
    }
   ],
   "source": [
    "dicto3 = {}\n",
    "for n in tqdm(unique):\n",
    "    dicto3.update({n: extra.query(\"HADM_ID == {}\".format(n))[\"ICD9_CODE\"].unique()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"num_stays\"] = data[\"subject_id\"].map(dicto)\n",
    "data[\"num_dis\"] = data[\"hadm_id\"].map(dicto2)\n",
    "data[\"dis\"] = data[\"hadm_id\"].map(dicto3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9309/9309 [00:54<00:00, 171.66it/s]\n",
      "100%|██████████| 11217/11217 [01:04<00:00, 173.71it/s]\n",
      "100%|██████████| 11217/11217 [01:04<00:00, 174.80it/s]\n"
     ]
    }
   ],
   "source": [
    "unique = test[\"subject_id\"].unique()\n",
    "dicto = {}\n",
    "for n in tqdm(unique):\n",
    "    dicto.update({n: len(extra.query(\"SUBJECT_ID == {}\".format(n))[\"HADM_ID\"].unique())})\n",
    "unique = test[\"hadm_id\"].unique()\n",
    "dicto2 = {}\n",
    "for n in tqdm(unique):\n",
    "    dicto2.update({n: len(extra.query(\"HADM_ID == {}\".format(n))[\"ICD9_CODE\"].unique())})\n",
    "dicto3 = {}\n",
    "for n in tqdm(unique):\n",
    "    dicto3.update({n: extra.query(\"HADM_ID == {}\".format(n))[\"ICD9_CODE\"].unique()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"num_stays\"] = test[\"subject_id\"].map(dicto)\n",
    "test[\"num_dis\"] = test[\"hadm_id\"].map(dicto2)\n",
    "test[\"dis\"] = test[\"hadm_id\"].map(dicto3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"nthstay\"] = test[\"hadm_id\"]*np.nan\n",
    "stacked = pd.concat([test,data], axis = 0)\n",
    "stacked[\"ADMITTIME\"] = pd.to_datetime(stacked[\"ADMITTIME\"])\n",
    "stacked.sort_values(by =\"ADMITTIME\",ascending = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25905/25905 [00:03<00:00, 7441.82it/s]\n"
     ]
    }
   ],
   "source": [
    "dicto = {}\n",
    "for n in tqdm(range(len(stacked))):\n",
    "    temp = stacked[\"subject_id\"].iloc[n]\n",
    "    keys = dicto.keys()\n",
    "    if temp in keys:\n",
    "        v = dicto[temp] + 1\n",
    "        dicto[temp] = v\n",
    "        stacked[\"nthstay\"].iloc[n] = v\n",
    "    else:\n",
    "        dicto[temp] = 1\n",
    "        stacked[\"nthstay\"].iloc[n] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = stacked.iloc[13840:]\n",
    "train_split = stacked.iloc[:13840]\n",
    "test_split.drop(\"LOS\", inplace = True, axis = 1)\n",
    "test = test_split.copy()\n",
    "data = train_split.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0gQxfGwpEq3",
    "outputId": "1eb7bb9d-0276-4697-a472-eaccd929a9ec"
   },
   "outputs": [],
   "source": [
    "test[\"AGE\"] = (pd.to_datetime(test[\"ADMITTIME\"])- pd.to_datetime(test[\"DOB\"])).dt.total_seconds()//3.154e+7\n",
    "data[\"AGE\"] = (pd.to_datetime(data[\"ADMITTIME\"])- pd.to_datetime(data[\"DOB\"])).dt.total_seconds()//3.154e+7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zo__YocIpEq4",
    "outputId": "65b9118c-e07a-4a04-abcb-03388038435e"
   },
   "outputs": [],
   "source": [
    "data[\"NAN\"] = (1*data.isna()).sum(axis = 1)\n",
    "test[\"NAN\"] = (1*test.isna()).sum(axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWhRBdx-pEq4",
    "outputId": "a27ba3a1-b95f-4fa0-81d8-cf71019557f8"
   },
   "outputs": [],
   "source": [
    "data.drop([\"subject_id\", \"hadm_id\", \"icustay_id\", \"ADMITTIME\"],axis =1, inplace= True)\n",
    "test.drop([\"subject_id\", \"hadm_id\", \"icustay_id\", \"ADMITTIME\"],axis =1, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "99cKjGyXpEq6"
   },
   "outputs": [],
   "source": [
    "data[\"MARITAL_STATUS\"] = data[\"MARITAL_STATUS\"] .replace(np.nan, 'UNKNOWN (DEFAULT)', regex=True)\n",
    "test[\"MARITAL_STATUS\"] = test[\"MARITAL_STATUS\"] .replace(np.nan, 'UNKNOWN (DEFAULT)', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_oH60M7LqC-p"
   },
   "outputs": [],
   "source": [
    "train.drop(\"LOS\", axis = 1, inplace = True)\n",
    "numerical = []\n",
    "for n in train.columns:\n",
    "  if train[n].dtype == \"int64\" or train[n].dtype ==\"float64\":\n",
    "    numerical.append(n)\n",
    "train.drop(\"DOB\", axis = 1, inplace = True)\n",
    "test.drop(\"DOB\", axis = 1, inplace = True)\n",
    "train.drop(\"RELIGION\", axis = 1, inplace = True)\n",
    "test.drop(\"RELIGION\", axis = 1, inplace = True)\n",
    "cat = list(set(train.columns) - set(train[numerical].columns))\n",
    "y = data[\"LOS\"]\n",
    "X = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"GENDER\"] = [1 if x == \"M\" else 0 for x in train[\"GENDER\"]]\n",
    "test[\"GENDER\"] = [1 if x == \"M\" else 0 for x in test[\"GENDER\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "enc = TargetEncoder(min_samples_leaf=5)\n",
    "at_train = train.copy()\n",
    "at_test = test.copy()\n",
    "at_train[\"ICD9_diagnosisT\"] = enc.fit_transform(at_train[\"ICD9_diagnosis\"], y)\n",
    "at_test[\"ICD9_diagnosisT\"] = enc.transform(at_test[\"ICD9_diagnosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_train = pd.concat([at_train[\"ICD9_diagnosisT\"], train[\"ICD9_diagnosis\"]], axis = 1)\n",
    "mix_test = pd.concat([at_test[\"ICD9_diagnosisT\"], test[\"ICD9_diagnosis\"]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICD9_diagnosisT</th>\n",
       "      <th>ICD9_diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>3.330470</td>\n",
       "      <td>95219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5349</th>\n",
       "      <td>3.683942</td>\n",
       "      <td>99812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>2.252513</td>\n",
       "      <td>41401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>2.400936</td>\n",
       "      <td>3942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>4.850595</td>\n",
       "      <td>56081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>3.330470</td>\n",
       "      <td>5111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117</th>\n",
       "      <td>3.330470</td>\n",
       "      <td>0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>3.330470</td>\n",
       "      <td>36522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>3.346895</td>\n",
       "      <td>57511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>3.330470</td>\n",
       "      <td>43381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1492 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ICD9_diagnosisT ICD9_diagnosis\n",
       "505           3.330470          95219\n",
       "5349          3.683942          99812\n",
       "10783         2.252513          41401\n",
       "9797          2.400936           3942\n",
       "6994          4.850595          56081\n",
       "...                ...            ...\n",
       "3274          3.330470           5111\n",
       "7117          3.330470           0059\n",
       "4442          3.330470          36522\n",
       "7189          3.346895          57511\n",
       "568           3.330470          43381\n",
       "\n",
       "[1492 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_train.drop_duplicates(subset=['ICD9_diagnosis'])\n",
    "mix_test.drop_duplicates(subset=['ICD9_diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_train.index = mix_train[\"ICD9_diagnosis\"]\n",
    "mix_train.drop([\"ICD9_diagnosis\"], axis = 1, inplace = True)\n",
    "dicto = mix_train.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13840/13840 [00:03<00:00, 3994.23it/s]\n",
      "100%|██████████| 12065/12065 [00:03<00:00, 3722.62it/s]\n"
     ]
    }
   ],
   "source": [
    "true_dicto = dicto[\"ICD9_diagnosisT\"]\n",
    "none_dicto = {None : np.nan}\n",
    "for n in tqdm(range(len(train))):\n",
    "    l = list(train[\"dis\"].iloc[n])\n",
    "    v = list(map(true_dicto.get, l))\n",
    "    v2 = [x for x in v if x != None]\n",
    "    v = [x if x != None else np.mean(v2) for x in v]\n",
    "    v = np.mean(v) *np.log(np.sum(v))\n",
    "    train[\"dis\"].iloc[n] = v\n",
    "    \n",
    "for n in tqdm(range(len(test))):\n",
    "    l = list(test[\"dis\"].iloc[n])\n",
    "    v = list(map(true_dicto.get, l))\n",
    "    v2 =  [x for x in v if x != None]\n",
    "    v = [x if x != None else np.mean(v2) for x in v]\n",
    "    v = np.mean(v) *np.log(np.sum(v))\n",
    "    test[\"dis\"].iloc[n] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dum = pd.get_dummies(train[['ADMISSION_TYPE','INSURANCE','MARITAL_STATUS','FIRST_CAREUNIT']])\n",
    "test_dum = pd.get_dummies(test[['ADMISSION_TYPE','INSURANCE','MARITAL_STATUS','FIRST_CAREUNIT']])\n",
    "train.drop(['ADMISSION_TYPE','INSURANCE','MARITAL_STATUS','FIRST_CAREUNIT'],axis = 1, inplace = True)\n",
    "test.drop(['ADMISSION_TYPE','INSURANCE','MARITAL_STATUS','FIRST_CAREUNIT'],axis = 1, inplace = True)\n",
    "train = pd.concat([train, train_dum], axis = 1)\n",
    "test = pd.concat([test, test_dum], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartRate_Min</th>\n",
       "      <th>HeartRate_Max</th>\n",
       "      <th>HeartRate_Mean</th>\n",
       "      <th>SysBP_Min</th>\n",
       "      <th>SysBP_Max</th>\n",
       "      <th>SysBP_Mean</th>\n",
       "      <th>DiasBP_Min</th>\n",
       "      <th>DiasBP_Max</th>\n",
       "      <th>DiasBP_Mean</th>\n",
       "      <th>MeanBP_Min</th>\n",
       "      <th>MeanBP_Max</th>\n",
       "      <th>MeanBP_Mean</th>\n",
       "      <th>RespRate_Min</th>\n",
       "      <th>RespRate_Max</th>\n",
       "      <th>RespRate_Mean</th>\n",
       "      <th>TempC_Min</th>\n",
       "      <th>TempC_Max</th>\n",
       "      <th>TempC_Mean</th>\n",
       "      <th>SpO2_Min</th>\n",
       "      <th>SpO2_Max</th>\n",
       "      <th>SpO2_Mean</th>\n",
       "      <th>Glucose_Min</th>\n",
       "      <th>Glucose_Max</th>\n",
       "      <th>Glucose_Mean</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>ICD9_diagnosis</th>\n",
       "      <th>num_stays</th>\n",
       "      <th>num_dis</th>\n",
       "      <th>dis</th>\n",
       "      <th>nthstay</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NAN</th>\n",
       "      <th>ADMISSION_TYPE_ELECTIVE</th>\n",
       "      <th>ADMISSION_TYPE_EMERGENCY</th>\n",
       "      <th>ADMISSION_TYPE_URGENT</th>\n",
       "      <th>INSURANCE_Government</th>\n",
       "      <th>INSURANCE_Medicaid</th>\n",
       "      <th>INSURANCE_Medicare</th>\n",
       "      <th>INSURANCE_Private</th>\n",
       "      <th>INSURANCE_Self Pay</th>\n",
       "      <th>MARITAL_STATUS_DIVORCED</th>\n",
       "      <th>MARITAL_STATUS_LIFE PARTNER</th>\n",
       "      <th>MARITAL_STATUS_MARRIED</th>\n",
       "      <th>MARITAL_STATUS_SEPARATED</th>\n",
       "      <th>MARITAL_STATUS_SINGLE</th>\n",
       "      <th>MARITAL_STATUS_UNKNOWN (DEFAULT)</th>\n",
       "      <th>MARITAL_STATUS_WIDOWED</th>\n",
       "      <th>FIRST_CAREUNIT_CCU</th>\n",
       "      <th>FIRST_CAREUNIT_CSRU</th>\n",
       "      <th>FIRST_CAREUNIT_MICU</th>\n",
       "      <th>FIRST_CAREUNIT_SICU</th>\n",
       "      <th>FIRST_CAREUNIT_TSICU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12647</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ACUTE MYELOGENOUS LEUKEMIA;DEEP VEIN THROMBOSIS</td>\n",
       "      <td>4538</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>12.9656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>5770</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>16.7597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>61.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.795455</td>\n",
       "      <td>71.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>100.673469</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>52.734694</td>\n",
       "      <td>38.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>67.224490</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24.204545</td>\n",
       "      <td>35.555556</td>\n",
       "      <td>38.333333</td>\n",
       "      <td>36.761111</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.309524</td>\n",
       "      <td>103.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>130.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>FEVER</td>\n",
       "      <td>2884</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>14.6397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>157.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>HEART FAILURE;MITRAL REGURGITATION;TRICUSPID R...</td>\n",
       "      <td>4242</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>10.3445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>78.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>92.032258</td>\n",
       "      <td>104.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>124.586207</td>\n",
       "      <td>56.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>70.586207</td>\n",
       "      <td>70.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>83.310345</td>\n",
       "      <td>12.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>21.387097</td>\n",
       "      <td>35.555556</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>35.952381</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.903226</td>\n",
       "      <td>145.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>179.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>BRBPR</td>\n",
       "      <td>56213</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>14.8215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HeartRate_Min  HeartRate_Max  HeartRate_Mean  SysBP_Min  SysBP_Max  \\\n",
       "12647            NaN            NaN             NaN        NaN        NaN   \n",
       "8274             NaN            NaN             NaN        NaN        NaN   \n",
       "118             61.0          106.0       76.795455       71.0      142.0   \n",
       "3727             NaN            NaN             NaN        NaN        NaN   \n",
       "10031           78.0          107.0       92.032258      104.0      145.0   \n",
       "\n",
       "       SysBP_Mean  DiasBP_Min  DiasBP_Max  DiasBP_Mean  MeanBP_Min  \\\n",
       "12647         NaN         NaN         NaN          NaN         NaN   \n",
       "8274          NaN         NaN         NaN          NaN         NaN   \n",
       "118    100.673469        20.0        96.0    52.734694        38.0   \n",
       "3727          NaN         NaN         NaN          NaN         NaN   \n",
       "10031  124.586207        56.0        95.0    70.586207        70.0   \n",
       "\n",
       "       MeanBP_Max  MeanBP_Mean  RespRate_Min  RespRate_Max  RespRate_Mean  \\\n",
       "12647         NaN          NaN           NaN           NaN            NaN   \n",
       "8274          NaN          NaN           NaN           NaN            NaN   \n",
       "118          98.0    67.224490          13.0          35.0      24.204545   \n",
       "3727          NaN          NaN           NaN           NaN            NaN   \n",
       "10031       107.0    83.310345          12.0          44.0      21.387097   \n",
       "\n",
       "       TempC_Min  TempC_Max  TempC_Mean  SpO2_Min  SpO2_Max  SpO2_Mean  \\\n",
       "12647        NaN        NaN         NaN       NaN       NaN        NaN   \n",
       "8274         NaN        NaN         NaN       NaN       NaN        NaN   \n",
       "118    35.555556  38.333333   36.761111      93.0     100.0  98.309524   \n",
       "3727         NaN        NaN         NaN       NaN       NaN        NaN   \n",
       "10031  35.555556  36.333333   35.952381      90.0     100.0  98.903226   \n",
       "\n",
       "       Glucose_Min  Glucose_Max  Glucose_Mean  GENDER               ETHNICITY  \\\n",
       "12647        119.0        119.0    119.000000       0                   WHITE   \n",
       "8274          86.0         88.0     87.000000       1                   WHITE   \n",
       "118          103.0        158.0    130.500000       0                   WHITE   \n",
       "3727          67.0        204.0    157.111111       0                   OTHER   \n",
       "10031        145.0        231.0    179.833333       1  BLACK/AFRICAN AMERICAN   \n",
       "\n",
       "                                               DIAGNOSIS ICD9_diagnosis  \\\n",
       "12647    ACUTE MYELOGENOUS LEUKEMIA;DEEP VEIN THROMBOSIS           4538   \n",
       "8274                                              SEPSIS           5770   \n",
       "118                                                FEVER           2884   \n",
       "3727   HEART FAILURE;MITRAL REGURGITATION;TRICUSPID R...           4242   \n",
       "10031                                              BRBPR          56213   \n",
       "\n",
       "       num_stays  num_dis      dis  nthstay   AGE  NAN  \\\n",
       "12647          1       16  12.9656      1.0  46.0   21   \n",
       "8274           2       39  16.7597      1.0  70.0   21   \n",
       "118            1       30  14.6397      1.0  70.0    0   \n",
       "3727           1       15  10.3445      1.0  84.0   21   \n",
       "10031          1       28  14.8215      1.0  79.0    0   \n",
       "\n",
       "       ADMISSION_TYPE_ELECTIVE  ADMISSION_TYPE_EMERGENCY  \\\n",
       "12647                        0                         1   \n",
       "8274                         0                         1   \n",
       "118                          0                         1   \n",
       "3727                         0                         1   \n",
       "10031                        0                         1   \n",
       "\n",
       "       ADMISSION_TYPE_URGENT  INSURANCE_Government  INSURANCE_Medicaid  \\\n",
       "12647                      0                     0                   0   \n",
       "8274                       0                     0                   0   \n",
       "118                        0                     0                   0   \n",
       "3727                       0                     0                   0   \n",
       "10031                      0                     0                   0   \n",
       "\n",
       "       INSURANCE_Medicare  INSURANCE_Private  INSURANCE_Self Pay  \\\n",
       "12647                   1                  0                   0   \n",
       "8274                    1                  0                   0   \n",
       "118                     1                  0                   0   \n",
       "3727                    1                  0                   0   \n",
       "10031                   1                  0                   0   \n",
       "\n",
       "       MARITAL_STATUS_DIVORCED  MARITAL_STATUS_LIFE PARTNER  \\\n",
       "12647                        0                            0   \n",
       "8274                         0                            0   \n",
       "118                          0                            0   \n",
       "3727                         0                            0   \n",
       "10031                        0                            0   \n",
       "\n",
       "       MARITAL_STATUS_MARRIED  MARITAL_STATUS_SEPARATED  \\\n",
       "12647                       0                         0   \n",
       "8274                        1                         0   \n",
       "118                         0                         0   \n",
       "3727                        1                         0   \n",
       "10031                       1                         0   \n",
       "\n",
       "       MARITAL_STATUS_SINGLE  MARITAL_STATUS_UNKNOWN (DEFAULT)  \\\n",
       "12647                      1                                 0   \n",
       "8274                       0                                 0   \n",
       "118                        1                                 0   \n",
       "3727                       0                                 0   \n",
       "10031                      0                                 0   \n",
       "\n",
       "       MARITAL_STATUS_WIDOWED  FIRST_CAREUNIT_CCU  FIRST_CAREUNIT_CSRU  \\\n",
       "12647                       0                   0                    0   \n",
       "8274                        0                   0                    0   \n",
       "118                         0                   0                    0   \n",
       "3727                        0                   0                    1   \n",
       "10031                       0                   0                    0   \n",
       "\n",
       "       FIRST_CAREUNIT_MICU  FIRST_CAREUNIT_SICU  FIRST_CAREUNIT_TSICU  \n",
       "12647                    1                    0                     0  \n",
       "8274                     0                    1                     0  \n",
       "118                      1                    0                     0  \n",
       "3727                     0                    0                     0  \n",
       "10031                    0                    1                     0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartRate_Min</th>\n",
       "      <th>HeartRate_Max</th>\n",
       "      <th>HeartRate_Mean</th>\n",
       "      <th>SysBP_Min</th>\n",
       "      <th>SysBP_Max</th>\n",
       "      <th>SysBP_Mean</th>\n",
       "      <th>DiasBP_Min</th>\n",
       "      <th>DiasBP_Max</th>\n",
       "      <th>DiasBP_Mean</th>\n",
       "      <th>MeanBP_Min</th>\n",
       "      <th>MeanBP_Max</th>\n",
       "      <th>MeanBP_Mean</th>\n",
       "      <th>RespRate_Min</th>\n",
       "      <th>RespRate_Max</th>\n",
       "      <th>RespRate_Mean</th>\n",
       "      <th>TempC_Min</th>\n",
       "      <th>TempC_Max</th>\n",
       "      <th>TempC_Mean</th>\n",
       "      <th>SpO2_Min</th>\n",
       "      <th>SpO2_Max</th>\n",
       "      <th>SpO2_Mean</th>\n",
       "      <th>Glucose_Min</th>\n",
       "      <th>Glucose_Max</th>\n",
       "      <th>Glucose_Mean</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>ICD9_diagnosis</th>\n",
       "      <th>num_stays</th>\n",
       "      <th>num_dis</th>\n",
       "      <th>dis</th>\n",
       "      <th>nthstay</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NAN</th>\n",
       "      <th>ADMISSION_TYPE_ELECTIVE</th>\n",
       "      <th>ADMISSION_TYPE_EMERGENCY</th>\n",
       "      <th>ADMISSION_TYPE_URGENT</th>\n",
       "      <th>INSURANCE_Government</th>\n",
       "      <th>INSURANCE_Medicaid</th>\n",
       "      <th>INSURANCE_Medicare</th>\n",
       "      <th>INSURANCE_Private</th>\n",
       "      <th>INSURANCE_Self Pay</th>\n",
       "      <th>MARITAL_STATUS_DIVORCED</th>\n",
       "      <th>MARITAL_STATUS_LIFE PARTNER</th>\n",
       "      <th>MARITAL_STATUS_MARRIED</th>\n",
       "      <th>MARITAL_STATUS_SEPARATED</th>\n",
       "      <th>MARITAL_STATUS_SINGLE</th>\n",
       "      <th>MARITAL_STATUS_UNKNOWN (DEFAULT)</th>\n",
       "      <th>MARITAL_STATUS_WIDOWED</th>\n",
       "      <th>FIRST_CAREUNIT_CCU</th>\n",
       "      <th>FIRST_CAREUNIT_CSRU</th>\n",
       "      <th>FIRST_CAREUNIT_MICU</th>\n",
       "      <th>FIRST_CAREUNIT_SICU</th>\n",
       "      <th>FIRST_CAREUNIT_TSICU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>93.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>114.190476</td>\n",
       "      <td>98.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>110.850000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>70.750000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>79.75000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>37.259259</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.047619</td>\n",
       "      <td>111.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>134.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>T 11 INTRADURAL TUMOR</td>\n",
       "      <td>95219</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>15.7965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5349</th>\n",
       "      <td>82.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>99.764706</td>\n",
       "      <td>86.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>117.224490</td>\n",
       "      <td>52.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>72.040816</td>\n",
       "      <td>46.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>90.92000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.053571</td>\n",
       "      <td>34.944444</td>\n",
       "      <td>36.888889</td>\n",
       "      <td>36.352941</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.411765</td>\n",
       "      <td>65.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>88.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>HISPANIC OR LATINO</td>\n",
       "      <td>PERICARDIAL HEMATOMA</td>\n",
       "      <td>99812</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>10.6515</td>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>56.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>59.724138</td>\n",
       "      <td>84.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>123.566667</td>\n",
       "      <td>49.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>70.533333</td>\n",
       "      <td>61.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>83.90000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.464286</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>37.277778</td>\n",
       "      <td>36.291667</td>\n",
       "      <td>91.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>95.714286</td>\n",
       "      <td>99.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>104.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>PATIENT DECLINED TO ANSWER</td>\n",
       "      <td>CHEST PAIN\\CARDIAC CATHETERIZATION</td>\n",
       "      <td>41401</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12.1354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>68.935484</td>\n",
       "      <td>90.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>111.343750</td>\n",
       "      <td>48.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>57.968750</td>\n",
       "      <td>58.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>73.90625</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>38.200000</td>\n",
       "      <td>37.090535</td>\n",
       "      <td>97.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.258065</td>\n",
       "      <td>85.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>120.352941</td>\n",
       "      <td>1</td>\n",
       "      <td>BLACK/CAPE VERDEAN</td>\n",
       "      <td>MITAL VALVE INSUFFICENCY\\MITRAL VALVE REPLACEM...</td>\n",
       "      <td>3942</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.78824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>82.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>93.714286</td>\n",
       "      <td>99.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>117.240000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>76.40000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.407407</td>\n",
       "      <td>36.555556</td>\n",
       "      <td>38.055556</td>\n",
       "      <td>37.174603</td>\n",
       "      <td>95.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>97.607143</td>\n",
       "      <td>137.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>ABDOMINAL PAIN</td>\n",
       "      <td>56081</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9.42877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HeartRate_Min  HeartRate_Max  HeartRate_Mean  SysBP_Min  SysBP_Max  \\\n",
       "505             93.0          148.0      114.190476       98.0      123.0   \n",
       "5349            82.0          124.0       99.764706       86.0      169.0   \n",
       "10783           56.0           67.0       59.724138       84.0      187.0   \n",
       "9797            59.0           78.0       68.935484       90.0      137.0   \n",
       "6994            82.0          107.0       93.714286       99.0      142.0   \n",
       "\n",
       "       SysBP_Mean  DiasBP_Min  DiasBP_Max  DiasBP_Mean  MeanBP_Min  \\\n",
       "505    110.850000        62.0       103.0    70.750000        70.0   \n",
       "5349   117.224490        52.0        91.0    72.040816        46.0   \n",
       "10783  123.566667        49.0        92.0    70.533333        61.0   \n",
       "9797   111.343750        48.0        71.0    57.968750        58.0   \n",
       "6994   117.240000        52.0        75.0    64.000000        68.0   \n",
       "\n",
       "       MeanBP_Max  MeanBP_Mean  RespRate_Min  RespRate_Max  RespRate_Mean  \\\n",
       "505         107.0     79.75000          16.0          32.0      25.333333   \n",
       "5349        123.0     90.92000           8.0          28.0      18.053571   \n",
       "10783       123.0     83.90000           9.0          17.0      14.464286   \n",
       "9797         91.0     73.90625          10.0          29.0      18.625000   \n",
       "6994         90.0     76.40000           8.0          20.0      14.407407   \n",
       "\n",
       "       TempC_Min  TempC_Max  TempC_Mean  SpO2_Min  SpO2_Max  SpO2_Mean  \\\n",
       "505    36.111111  38.500000   37.259259      96.0     100.0  99.047619   \n",
       "5349   34.944444  36.888889   36.352941      96.0     100.0  99.411765   \n",
       "10783  35.333333  37.277778   36.291667      91.0      99.0  95.714286   \n",
       "9797   36.000000  38.200000   37.090535      97.0     100.0  99.258065   \n",
       "6994   36.555556  38.055556   37.174603      95.0      99.0  97.607143   \n",
       "\n",
       "       Glucose_Min  Glucose_Max  Glucose_Mean  GENDER  \\\n",
       "505          111.0        145.0    134.250000       0   \n",
       "5349          65.0        142.0     88.833333       1   \n",
       "10783         99.0        110.0    104.500000       1   \n",
       "9797          85.0        212.0    120.352941       1   \n",
       "6994         137.0        187.0    162.000000       1   \n",
       "\n",
       "                        ETHNICITY  \\\n",
       "505                         WHITE   \n",
       "5349           HISPANIC OR LATINO   \n",
       "10783  PATIENT DECLINED TO ANSWER   \n",
       "9797           BLACK/CAPE VERDEAN   \n",
       "6994       BLACK/AFRICAN AMERICAN   \n",
       "\n",
       "                                               DIAGNOSIS ICD9_diagnosis  \\\n",
       "505                                T 11 INTRADURAL TUMOR          95219   \n",
       "5349                                PERICARDIAL HEMATOMA          99812   \n",
       "10783                 CHEST PAIN\\CARDIAC CATHETERIZATION          41401   \n",
       "9797   MITAL VALVE INSUFFICENCY\\MITRAL VALVE REPLACEM...           3942   \n",
       "6994                                      ABDOMINAL PAIN          56081   \n",
       "\n",
       "       num_stays  num_dis      dis  nthstay   AGE  NAN  \\\n",
       "505            1       23  15.7965      1.0  45.0    0   \n",
       "5349           7       12  10.6515      6.0  34.0    0   \n",
       "10783          1       19  12.1354      1.0  76.0    0   \n",
       "9797           1        5  4.78824      1.0  37.0    0   \n",
       "6994           1        7  9.42877      1.0  46.0    0   \n",
       "\n",
       "       ADMISSION_TYPE_ELECTIVE  ADMISSION_TYPE_EMERGENCY  \\\n",
       "505                          0                         1   \n",
       "5349                         0                         1   \n",
       "10783                        0                         1   \n",
       "9797                         1                         0   \n",
       "6994                         0                         1   \n",
       "\n",
       "       ADMISSION_TYPE_URGENT  INSURANCE_Government  INSURANCE_Medicaid  \\\n",
       "505                        0                     0                   1   \n",
       "5349                       0                     0                   0   \n",
       "10783                      0                     0                   0   \n",
       "9797                       0                     0                   0   \n",
       "6994                       0                     0                   0   \n",
       "\n",
       "       INSURANCE_Medicare  INSURANCE_Private  INSURANCE_Self Pay  \\\n",
       "505                     0                  0                   0   \n",
       "5349                    1                  0                   0   \n",
       "10783                   1                  0                   0   \n",
       "9797                    0                  1                   0   \n",
       "6994                    0                  1                   0   \n",
       "\n",
       "       MARITAL_STATUS_DIVORCED  MARITAL_STATUS_LIFE PARTNER  \\\n",
       "505                          0                            0   \n",
       "5349                         1                            0   \n",
       "10783                        0                            0   \n",
       "9797                         0                            0   \n",
       "6994                         0                            0   \n",
       "\n",
       "       MARITAL_STATUS_MARRIED  MARITAL_STATUS_SEPARATED  \\\n",
       "505                         1                         0   \n",
       "5349                        0                         0   \n",
       "10783                       0                         0   \n",
       "9797                        0                         0   \n",
       "6994                        0                         0   \n",
       "\n",
       "       MARITAL_STATUS_SINGLE  MARITAL_STATUS_UNKNOWN (DEFAULT)  \\\n",
       "505                        0                                 0   \n",
       "5349                       0                                 0   \n",
       "10783                      0                                 0   \n",
       "9797                       1                                 0   \n",
       "6994                       1                                 0   \n",
       "\n",
       "       MARITAL_STATUS_WIDOWED  FIRST_CAREUNIT_CCU  FIRST_CAREUNIT_CSRU  \\\n",
       "505                         0                   0                    0   \n",
       "5349                        0                   0                    1   \n",
       "10783                       1                   1                    0   \n",
       "9797                        0                   0                    1   \n",
       "6994                        0                   0                    0   \n",
       "\n",
       "       FIRST_CAREUNIT_MICU  FIRST_CAREUNIT_SICU  FIRST_CAREUNIT_TSICU  \n",
       "505                      0                    0                     1  \n",
       "5349                     0                    0                     0  \n",
       "10783                    0                    0                     0  \n",
       "9797                     0                    0                     0  \n",
       "6994                     1                    0                     0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f = test.copy()\n",
    "train_f = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_f.copy()\n",
    "test = test_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"ETHNICITY\"],axis = 1, inplace = True)\n",
    "test.drop([\"ETHNICITY\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMFVz5dppEq-",
    "outputId": "b31a863c-5745-45a2-8f7a-2228b767fdb7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "from keras.metrics import MeanAbsoluteError\n",
    "from keras import layers as l\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "#!pip install category_encoders\n",
    "\n",
    "from sklearn.model_selection import  train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "6kc8dKtxpErA"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state = 2137)\n",
    "X_trainf, X_testf, y_trainf, y_testf= X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [\"ICD9_diagnosis\", \"DIAGNOSIS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jSwcRltfpErA",
    "outputId": "70b0c127-07b2-43d7-c81b-b5c66495c635"
   },
   "outputs": [],
   "source": [
    "sc = RobustScaler()\n",
    "enc = TargetEncoder(min_samples_leaf=5)\n",
    "X_train[cat] = enc.fit_transform(X_train[cat], y_train) \n",
    "test[cat] = enc.transform(test[cat])\n",
    "X_test[cat] = enc.transform(X_test[cat])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartRate_Min</th>\n",
       "      <th>HeartRate_Max</th>\n",
       "      <th>HeartRate_Mean</th>\n",
       "      <th>SysBP_Min</th>\n",
       "      <th>SysBP_Max</th>\n",
       "      <th>SysBP_Mean</th>\n",
       "      <th>DiasBP_Min</th>\n",
       "      <th>DiasBP_Max</th>\n",
       "      <th>DiasBP_Mean</th>\n",
       "      <th>MeanBP_Min</th>\n",
       "      <th>MeanBP_Max</th>\n",
       "      <th>MeanBP_Mean</th>\n",
       "      <th>RespRate_Min</th>\n",
       "      <th>RespRate_Max</th>\n",
       "      <th>RespRate_Mean</th>\n",
       "      <th>TempC_Min</th>\n",
       "      <th>TempC_Max</th>\n",
       "      <th>TempC_Mean</th>\n",
       "      <th>SpO2_Min</th>\n",
       "      <th>SpO2_Max</th>\n",
       "      <th>SpO2_Mean</th>\n",
       "      <th>Glucose_Min</th>\n",
       "      <th>Glucose_Max</th>\n",
       "      <th>Glucose_Mean</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>ICD9_diagnosis</th>\n",
       "      <th>num_stays</th>\n",
       "      <th>num_dis</th>\n",
       "      <th>dis</th>\n",
       "      <th>nthstay</th>\n",
       "      <th>AGE</th>\n",
       "      <th>NAN</th>\n",
       "      <th>ADMISSION_TYPE_ELECTIVE</th>\n",
       "      <th>ADMISSION_TYPE_EMERGENCY</th>\n",
       "      <th>ADMISSION_TYPE_URGENT</th>\n",
       "      <th>INSURANCE_Government</th>\n",
       "      <th>INSURANCE_Medicaid</th>\n",
       "      <th>INSURANCE_Medicare</th>\n",
       "      <th>INSURANCE_Private</th>\n",
       "      <th>INSURANCE_Self Pay</th>\n",
       "      <th>MARITAL_STATUS_DIVORCED</th>\n",
       "      <th>MARITAL_STATUS_LIFE PARTNER</th>\n",
       "      <th>MARITAL_STATUS_MARRIED</th>\n",
       "      <th>MARITAL_STATUS_SEPARATED</th>\n",
       "      <th>MARITAL_STATUS_SINGLE</th>\n",
       "      <th>MARITAL_STATUS_UNKNOWN (DEFAULT)</th>\n",
       "      <th>MARITAL_STATUS_WIDOWED</th>\n",
       "      <th>FIRST_CAREUNIT_CCU</th>\n",
       "      <th>FIRST_CAREUNIT_CSRU</th>\n",
       "      <th>FIRST_CAREUNIT_MICU</th>\n",
       "      <th>FIRST_CAREUNIT_SICU</th>\n",
       "      <th>FIRST_CAREUNIT_TSICU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>68.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>85.931034</td>\n",
       "      <td>99.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>127.481481</td>\n",
       "      <td>65.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>76.444444</td>\n",
       "      <td>73.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>87.962963</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.909091</td>\n",
       "      <td>35.444444</td>\n",
       "      <td>38.111111</td>\n",
       "      <td>36.388889</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.714286</td>\n",
       "      <td>55.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>114.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>3.349635</td>\n",
       "      <td>1.577337</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>11.1059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>67.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>89.311111</td>\n",
       "      <td>83.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>114.118644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>59.220339</td>\n",
       "      <td>54.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>73.813559</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.297872</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>37.666667</td>\n",
       "      <td>36.762500</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.044444</td>\n",
       "      <td>61.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>141.850000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.283031</td>\n",
       "      <td>3.282629</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>66.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>74.277778</td>\n",
       "      <td>100.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>124.481481</td>\n",
       "      <td>42.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>54.259259</td>\n",
       "      <td>57.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>75.162791</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.822222</td>\n",
       "      <td>35.111111</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>35.764957</td>\n",
       "      <td>88.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.972222</td>\n",
       "      <td>106.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>133.571429</td>\n",
       "      <td>1</td>\n",
       "      <td>3.155440</td>\n",
       "      <td>5.988959</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10695</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.119192</td>\n",
       "      <td>3.458921</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>60.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>81.550725</td>\n",
       "      <td>72.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>108.956522</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>47.130435</td>\n",
       "      <td>49.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>64.223881</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.416667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>126.305556</td>\n",
       "      <td>1</td>\n",
       "      <td>3.349635</td>\n",
       "      <td>5.006970</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>11.4935</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HeartRate_Min  HeartRate_Max  HeartRate_Mean  SysBP_Min  SysBP_Max  \\\n",
       "4745            68.0          107.0       85.931034       99.0      154.0   \n",
       "6999            67.0          106.0       89.311111       83.0      147.0   \n",
       "9355            66.0           91.0       74.277778      100.0      161.0   \n",
       "10695            NaN            NaN             NaN        NaN        NaN   \n",
       "7204            60.0           96.0       81.550725       72.0      144.0   \n",
       "\n",
       "       SysBP_Mean  DiasBP_Min  DiasBP_Max  DiasBP_Mean  MeanBP_Min  \\\n",
       "4745   127.481481        65.0        96.0    76.444444        73.0   \n",
       "6999   114.118644        40.0       119.0    59.220339        54.0   \n",
       "9355   124.481481        42.0        68.0    54.259259        57.0   \n",
       "10695         NaN         NaN         NaN          NaN         NaN   \n",
       "7204   108.956522        35.0        58.0    47.130435        49.0   \n",
       "\n",
       "       MeanBP_Max  MeanBP_Mean  RespRate_Min  RespRate_Max  RespRate_Mean  \\\n",
       "4745        110.0    87.962963          10.0          20.0      16.909091   \n",
       "6999        124.0    73.813559           7.0          20.0      13.297872   \n",
       "9355        102.0    75.162791           9.0          33.0      22.822222   \n",
       "10695         NaN          NaN           NaN           NaN            NaN   \n",
       "7204         77.0    64.223881           6.0          38.0      17.416667   \n",
       "\n",
       "       TempC_Min  TempC_Max  TempC_Mean  SpO2_Min  SpO2_Max  SpO2_Mean  \\\n",
       "4745   35.444444  38.111111   36.388889      92.0     100.0  97.714286   \n",
       "6999   36.000000  37.666667   36.762500      94.0     100.0  98.044444   \n",
       "9355   35.111111  36.277778   35.764957      88.0     100.0  95.972222   \n",
       "10695        NaN        NaN         NaN       NaN       NaN        NaN   \n",
       "7204         NaN        NaN         NaN      97.0     100.0  99.500000   \n",
       "\n",
       "       Glucose_Min  Glucose_Max  Glucose_Mean  GENDER  DIAGNOSIS  \\\n",
       "4745          55.0        153.0    114.833333       1   3.349635   \n",
       "6999          61.0        242.0    141.850000       1   3.283031   \n",
       "9355         106.0        164.0    133.571429       1   3.155440   \n",
       "10695        194.0        194.0    194.000000       0   3.119192   \n",
       "7204          75.0        195.0    126.305556       1   3.349635   \n",
       "\n",
       "       ICD9_diagnosis  num_stays  num_dis      dis  nthstay   AGE  NAN  \\\n",
       "4745         1.577337          2       21  11.1059      2.0  37.0    0   \n",
       "6999         3.282629          1       13   9.0921      1.0  69.0    0   \n",
       "9355         5.988959          1       18  13.0468      1.0  77.0    0   \n",
       "10695        3.458921          1        9    11.75      1.0  91.0   21   \n",
       "7204         5.006970          1       19  11.4935      1.0  77.0    3   \n",
       "\n",
       "       ADMISSION_TYPE_ELECTIVE  ADMISSION_TYPE_EMERGENCY  \\\n",
       "4745                         0                         1   \n",
       "6999                         1                         0   \n",
       "9355                         0                         1   \n",
       "10695                        0                         1   \n",
       "7204                         0                         1   \n",
       "\n",
       "       ADMISSION_TYPE_URGENT  INSURANCE_Government  INSURANCE_Medicaid  \\\n",
       "4745                       0                     0                   0   \n",
       "6999                       0                     0                   0   \n",
       "9355                       0                     0                   0   \n",
       "10695                      0                     0                   0   \n",
       "7204                       0                     0                   0   \n",
       "\n",
       "       INSURANCE_Medicare  INSURANCE_Private  INSURANCE_Self Pay  \\\n",
       "4745                    1                  0                   0   \n",
       "6999                    1                  0                   0   \n",
       "9355                    1                  0                   0   \n",
       "10695                   1                  0                   0   \n",
       "7204                    1                  0                   0   \n",
       "\n",
       "       MARITAL_STATUS_DIVORCED  MARITAL_STATUS_LIFE PARTNER  \\\n",
       "4745                         0                            0   \n",
       "6999                         1                            0   \n",
       "9355                         0                            0   \n",
       "10695                        0                            0   \n",
       "7204                         0                            0   \n",
       "\n",
       "       MARITAL_STATUS_MARRIED  MARITAL_STATUS_SEPARATED  \\\n",
       "4745                        0                         0   \n",
       "6999                        0                         0   \n",
       "9355                        1                         0   \n",
       "10695                       0                         0   \n",
       "7204                        1                         0   \n",
       "\n",
       "       MARITAL_STATUS_SINGLE  MARITAL_STATUS_UNKNOWN (DEFAULT)  \\\n",
       "4745                       1                                 0   \n",
       "6999                       0                                 0   \n",
       "9355                       0                                 0   \n",
       "10695                      0                                 0   \n",
       "7204                       0                                 0   \n",
       "\n",
       "       MARITAL_STATUS_WIDOWED  FIRST_CAREUNIT_CCU  FIRST_CAREUNIT_CSRU  \\\n",
       "4745                        0                   0                    0   \n",
       "6999                        0                   0                    1   \n",
       "9355                        0                   0                    0   \n",
       "10695                       1                   0                    1   \n",
       "7204                        0                   0                    1   \n",
       "\n",
       "       FIRST_CAREUNIT_MICU  FIRST_CAREUNIT_SICU  FIRST_CAREUNIT_TSICU  \n",
       "4745                     1                    0                     0  \n",
       "6999                     0                    0                     0  \n",
       "9355                     1                    0                     0  \n",
       "10695                    0                    0                     0  \n",
       "7204                     0                    0                     0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RespRate_Min',\n",
       " 'MeanBP_Mean',\n",
       " 'Glucose_Max',\n",
       " 'AGE',\n",
       " 'num_dis',\n",
       " 'Glucose_Min',\n",
       " 'HeartRate_Mean',\n",
       " 'DiasBP_Min',\n",
       " 'MeanBP_Max',\n",
       " 'RespRate_Max',\n",
       " 'DiasBP_Max',\n",
       " 'dis',\n",
       " 'HeartRate_Max',\n",
       " 'SysBP_Mean',\n",
       " 'HeartRate_Min',\n",
       " 'TempC_Max',\n",
       " 'DIAGNOSIS',\n",
       " 'DiasBP_Mean',\n",
       " 'SpO2_Max',\n",
       " 'RespRate_Mean',\n",
       " 'SysBP_Max',\n",
       " 'nthstay',\n",
       " 'TempC_Mean',\n",
       " 'num_stays',\n",
       " 'TempC_Min',\n",
       " 'NAN',\n",
       " 'SpO2_Mean',\n",
       " 'MeanBP_Min',\n",
       " 'Glucose_Mean',\n",
       " 'SpO2_Min',\n",
       " 'ICD9_diagnosis',\n",
       " 'SysBP_Min']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum = list(train_dum.columns)\n",
    "dum.append(\"GENDER\")\n",
    "ss = list(set(X_train.columns) - set(dum))\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[ss] =sc.fit_transform(X_train[ss])\n",
    "X_test[ss] = sc.transform(X_test[ss])\n",
    "\n",
    "test[ss] = sc.transform(test[ss]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11072, 53), (2768, 53), (11072,), (2768,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainf.shape, X_testf.shape, y_trainf.shape, y_testf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD IMPORTS THEN YOU CAN START FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"y_train=pd.read_csv(\"y_trainS.csv\")\n",
    "y_train.drop(\"Unnamed: 0\", inplace = True, axis = 1)\n",
    "y_train = y_train.values\n",
    "y_test=pd.read_csv(\"y_testS.csv\")\n",
    "y_test.drop(\"Unnamed: 0\", inplace = True, axis = 1)\n",
    "y_test = y_test.values\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing prior to running GAIN to generatemissing values - https://arxiv.org/pdf/1806.02920.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"X_train=pd.read_csv(\"X_train_imputed.csv\")\n",
    "X_train.drop(\"Unnamed: 0\", inplace = True, axis = 1)\n",
    "X_train = X_train.values\n",
    "\n",
    "X_test=pd.read_csv(\"X_test_imputed.csv\")\n",
    "X_test.drop(\"Unnamed: 0\", inplace = True, axis = 1)\n",
    "X_test = X_test.values\n",
    "\n",
    "test=pd.read_csv(\"test_imputed.csv\")\n",
    "test.drop(\"Unnamed: 0\", inplace = True, axis = 1)\n",
    "test = test.values\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11072, 53), (2768, 53), (11072,), (2768,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=1, weights=\"uniform\")\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "test = imputer.transform(test)\n",
    "np.isnan(X_train).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUTS = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTuner(kt.tuners.Hyperband):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 32, 256, step=32)\n",
    "        super(MyTuner, self).run_trial(trial, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "        a = (y_pred - y_true)\n",
    "        #a = tf.where(tf.less_equal(a, 1), a, a**2)\n",
    "        return (tf.reduce_mean(abs(a))) \n",
    "\n",
    "\n",
    "\n",
    "def reg(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    hp_reg = hp.Float('regularizers', min_value=0.000001, max_value=5, default=0.01,sampling='LOG') \n",
    "    \n",
    "    model.add(l.Dense(units = hp.Int('units_0', min_value = 32, max_value = 192, step = 16), use_bias=True,  input_dim=N_INPUTS, activation=hp.Choice('dense_activation_0',values=['relu', 'selu'],default='selu'),\n",
    "                       kernel_regularizer=regularizers.l2(l2=hp_reg)))\n",
    "    \n",
    "    model.add(l.Dense(units = hp.Int('units_1', min_value = 32, max_value = 192, step = 16),\n",
    "                      use_bias=True,  activation=hp.Choice('dense_activation_1',values=['relu', 'selu','elu'],default='selu'),\n",
    "                      kernel_regularizer=regularizers.l2(l2=hp_reg)))\n",
    "    \n",
    "    model.add(l.Dropout(rate = hp.Float('dropout_1',min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n",
    "    model.add(l.Dense(units = hp.Int('units_2', min_value = 32, max_value = 192, step = 16), \n",
    "                      use_bias=True, activation=hp.Choice('dense_activation_2',values=['relu', 'selu','elu'],default='selu'),\n",
    "                       kernel_regularizer=regularizers.l2(l2=hp_reg)))\n",
    "    \n",
    "    model.add(l.Dropout(rate = hp.Float('dropout_2',min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n",
    "    model.add(l.Dense(units = hp.Int('units_3', min_value = 32, max_value = 192, step = 16), \n",
    "                      use_bias=True, activation=hp.Choice('dense_activation_3',values=['relu', 'selu','elu'],default='selu'),\n",
    "                       kernel_regularizer=regularizers.l2(l2=hp_reg)))\n",
    "    \n",
    "    model.add(l.Dropout(rate = hp.Float('dropout_3',min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n",
    "    model.add(l.Dense(units = hp.Int('units_4', min_value = 16, max_value = 128, step = 16),\n",
    "                      use_bias=True, activation=hp.Choice('dense_activation_4',values=['relu', 'selu','elu'],default='selu'),\n",
    "                       kernel_regularizer=regularizers.l2(hp_reg)))\n",
    "    \n",
    "    model.add(l.Dropout(rate = hp.Float('dropout_4',min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n",
    "    model.add(l.Dense(1, activation =\"relu\"))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4,max_value=1e-2,default=1e-3, sampling='LOG')),loss=['mae'],metrics=['mae'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 220 Complete [00h 00m 12s]\n",
      "mae: 2.136881113052368\n",
      "\n",
      "Best mae So Far: 1.6651052236557007\n",
      "Total elapsed time: 00h 13m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = MyTuner(reg, objective = \"mae\", factor=5, hyperband_iterations=5, seed = 2137, max_epochs = 25,overwrite=True, project_name = 'N')\n",
    "tuner.search(X_train, y_train, epochs = 20, validation_data = (X_test, y_test),callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 2ms/step - loss: 1.8596 - mae: 1.8499\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "loss, mae = best_model.evaluate(X_test, y_testL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 80)                4320      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                5184      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 192)               12480     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 37,505\n",
      "Trainable params: 37,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def sanityN():\n",
    "    model = Sequential()\n",
    "    reg = 1.4942368573857448e-05\n",
    "    model.add(l.Dense(units= 80, use_bias=True,  input_dim=N_INPUTS, activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(l2=reg)))\n",
    "    \n",
    "    model.add(l.Dense(units = 64,\n",
    "                      use_bias=True,  activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(l2=reg)))\n",
    "    \n",
    "    model.add(l.Dropout(rate = 0.2))\n",
    "    model.add(l.Dense(units =192, \n",
    "                      use_bias=True, activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(l2=reg)))\n",
    "    \n",
    "    model.add(l.Dropout(rate =0.3))\n",
    "    model.add(l.Dense(units= 64, \n",
    "                      use_bias=True, activation='elu',\n",
    "                       kernel_regularizer=regularizers.l2(l2=reg)))\n",
    "    \n",
    "    model.add(l.Dropout(rate = 0.3))\n",
    "    model.add(l.Dense(units = 48,\n",
    "                      use_bias=True, activation='elu',\n",
    "                       kernel_regularizer=regularizers.l2(reg)))\n",
    "    \n",
    "    model.add(l.Dropout(rate = 0.05))\n",
    "    model.add(l.Dense(1, activation =\"relu\"))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(0.004215595254424248),loss='mae',metrics='mae')\n",
    "    return model\n",
    "sanityN().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\N\n",
      "Showing 10 best trials\n",
      "Objective(name='mae', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 1.4942368573857448e-05\n",
      "units_0: 80\n",
      "dense_activation_0: relu\n",
      "units_1: 64\n",
      "dense_activation_1: relu\n",
      "dropout_1: 0.2\n",
      "units_2: 192\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.30000000000000004\n",
      "units_3: 64\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.30000000000000004\n",
      "units_4: 48\n",
      "dense_activation_4: elu\n",
      "dropout_4: 0.05\n",
      "learning_rate: 0.004215595254424248\n",
      "batch_size: 160\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 1f2d9e4e1d813e52a337f7a2872a3fab\n",
      "Score: 1.6651052236557007\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.0006136572307132355\n",
      "units_0: 96\n",
      "dense_activation_0: relu\n",
      "units_1: 160\n",
      "dense_activation_1: elu\n",
      "dropout_1: 0.35000000000000003\n",
      "units_2: 64\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.35000000000000003\n",
      "units_3: 80\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.1\n",
      "units_4: 112\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.35000000000000003\n",
      "learning_rate: 0.0025289532699025036\n",
      "batch_size: 192\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 1.674542784690857\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.0009375337116720802\n",
      "units_0: 144\n",
      "dense_activation_0: relu\n",
      "units_1: 128\n",
      "dense_activation_1: relu\n",
      "dropout_1: 0.4\n",
      "units_2: 64\n",
      "dense_activation_2: elu\n",
      "dropout_2: 0.15000000000000002\n",
      "units_3: 160\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.25\n",
      "units_4: 32\n",
      "dense_activation_4: selu\n",
      "dropout_4: 0.0\n",
      "learning_rate: 0.00018942177895293755\n",
      "batch_size: 32\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 1.7002357244491577\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 5.390077271246416e-05\n",
      "units_0: 64\n",
      "dense_activation_0: relu\n",
      "units_1: 80\n",
      "dense_activation_1: relu\n",
      "dropout_1: 0.4\n",
      "units_2: 48\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.1\n",
      "units_3: 176\n",
      "dense_activation_3: relu\n",
      "dropout_3: 0.1\n",
      "units_4: 96\n",
      "dense_activation_4: selu\n",
      "dropout_4: 0.25\n",
      "learning_rate: 0.0030117036523843108\n",
      "batch_size: 160\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 1.7094123363494873\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.0030302742343263755\n",
      "units_0: 80\n",
      "dense_activation_0: relu\n",
      "units_1: 80\n",
      "dense_activation_1: elu\n",
      "dropout_1: 0.35000000000000003\n",
      "units_2: 32\n",
      "dense_activation_2: elu\n",
      "dropout_2: 0.35000000000000003\n",
      "units_3: 96\n",
      "dense_activation_3: relu\n",
      "dropout_3: 0.5\n",
      "units_4: 48\n",
      "dense_activation_4: elu\n",
      "dropout_4: 0.1\n",
      "learning_rate: 0.0006564307435068998\n",
      "batch_size: 64\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 1.7211822271347046\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 1.1494203550939374e-05\n",
      "units_0: 192\n",
      "dense_activation_0: selu\n",
      "units_1: 112\n",
      "dense_activation_1: elu\n",
      "dropout_1: 0.0\n",
      "units_2: 128\n",
      "dense_activation_2: elu\n",
      "dropout_2: 0.05\n",
      "units_3: 96\n",
      "dense_activation_3: selu\n",
      "dropout_3: 0.2\n",
      "units_4: 64\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.15000000000000002\n",
      "learning_rate: 0.0019171366131843321\n",
      "batch_size: 96\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 6d75bdde662a3055bcbd336b38d86695\n",
      "Score: 1.7314074039459229\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 4.763832489065153e-05\n",
      "units_0: 176\n",
      "dense_activation_0: relu\n",
      "units_1: 112\n",
      "dense_activation_1: elu\n",
      "dropout_1: 0.1\n",
      "units_2: 192\n",
      "dense_activation_2: selu\n",
      "dropout_2: 0.35000000000000003\n",
      "units_3: 144\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.25\n",
      "units_4: 96\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.4\n",
      "learning_rate: 0.0009279273187502759\n",
      "batch_size: 224\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 49d42459800b239d1823b6dbc9106b9f\n",
      "Score: 1.7364965677261353\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.004612995290521153\n",
      "units_0: 144\n",
      "dense_activation_0: relu\n",
      "units_1: 32\n",
      "dense_activation_1: selu\n",
      "dropout_1: 0.1\n",
      "units_2: 128\n",
      "dense_activation_2: selu\n",
      "dropout_2: 0.0\n",
      "units_3: 144\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.35000000000000003\n",
      "units_4: 32\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.05\n",
      "learning_rate: 0.0004209841475278669\n",
      "batch_size: 96\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 8acf86a25837f15cbd78163415eceace\n",
      "Score: 1.7392328977584839\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.00017267134349628982\n",
      "units_0: 80\n",
      "dense_activation_0: selu\n",
      "units_1: 112\n",
      "dense_activation_1: relu\n",
      "dropout_1: 0.1\n",
      "units_2: 96\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.25\n",
      "units_3: 96\n",
      "dense_activation_3: selu\n",
      "dropout_3: 0.35000000000000003\n",
      "units_4: 80\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.1\n",
      "learning_rate: 0.0034557203461527738\n",
      "batch_size: 128\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 7264322fa422fede6aa6884f4f109a04\n",
      "Score: 1.7421603202819824\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 1.284080963659891e-06\n",
      "units_0: 80\n",
      "dense_activation_0: relu\n",
      "units_1: 64\n",
      "dense_activation_1: relu\n",
      "dropout_1: 0.25\n",
      "units_2: 128\n",
      "dense_activation_2: elu\n",
      "dropout_2: 0.30000000000000004\n",
      "units_3: 112\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.15000000000000002\n",
      "units_4: 96\n",
      "dense_activation_4: elu\n",
      "dropout_4: 0.25\n",
      "learning_rate: 0.001620301758122103\n",
      "batch_size: 128\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 14b0b79790c9582e953f786a95d969ed\n",
      "Score: 1.7423194646835327\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "modelN = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 80)                4320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                5184      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 192)               12480     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 37,505\n",
      "Trainable params: 37,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "58/58 [==============================] - 1s 8ms/step - loss: 2.1565 - mae: 2.1507 - val_loss: 1.8142 - val_mae: 1.8082\n",
      "Epoch 2/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.9190 - mae: 1.9130 - val_loss: 1.7867 - val_mae: 1.7806\n",
      "Epoch 3/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.8364 - mae: 1.8302 - val_loss: 1.7741 - val_mae: 1.7678\n",
      "Epoch 4/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.8492 - mae: 1.8429 - val_loss: 1.7821 - val_mae: 1.7757\n",
      "Epoch 5/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.7741 - mae: 1.7676 - val_loss: 1.8162 - val_mae: 1.8095\n",
      "Epoch 6/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7882 - mae: 1.7815 - val_loss: 1.8117 - val_mae: 1.8048\n",
      "Epoch 7/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7533 - mae: 1.7464 - val_loss: 1.7740 - val_mae: 1.7670\n",
      "Epoch 8/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7945 - mae: 1.7874 - val_loss: 1.9107 - val_mae: 1.9034\n",
      "Epoch 9/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7841 - mae: 1.7768 - val_loss: 1.8223 - val_mae: 1.8147\n",
      "Epoch 10/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.7186 - mae: 1.7110 - val_loss: 1.7994 - val_mae: 1.7916\n",
      "Epoch 11/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7190 - mae: 1.7111 - val_loss: 1.8059 - val_mae: 1.7977\n",
      "Epoch 12/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.6790 - mae: 1.6708 - val_loss: 1.7921 - val_mae: 1.7836\n",
      "Epoch 13/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.6985 - mae: 1.6900 - val_loss: 1.7820 - val_mae: 1.7733\n",
      "Epoch 14/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6605 - mae: 1.6516 - val_loss: 1.8037 - val_mae: 1.7947\n",
      "Epoch 15/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.6603 - mae: 1.6512 - val_loss: 1.8362 - val_mae: 1.8269\n",
      "Epoch 16/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.6060 - mae: 1.5966 - val_loss: 1.8101 - val_mae: 1.8005\n",
      "Epoch 17/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6061 - mae: 1.5964 - val_loss: 1.8255 - val_mae: 1.8156\n",
      "Epoch 18/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6180 - mae: 1.6080 - val_loss: 1.8510 - val_mae: 1.8408\n",
      "Epoch 19/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5637 - mae: 1.5534 - val_loss: 1.9011 - val_mae: 1.8907\n",
      "Epoch 20/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6052 - mae: 1.5946 - val_loss: 1.8304 - val_mae: 1.8196\n",
      "Epoch 21/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5752 - mae: 1.5643 - val_loss: 1.8644 - val_mae: 1.8532\n",
      "Epoch 22/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5762 - mae: 1.5650 - val_loss: 1.8275 - val_mae: 1.8161\n",
      "Epoch 23/25\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5591 - mae: 1.5475 - val_loss: 1.8032 - val_mae: 1.7915\n",
      "Epoch 24/25\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5237 - mae: 1.5118 - val_loss: 1.8957 - val_mae: 1.8836\n",
      "Epoch 25/25\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 1.5626 - mae: 1.5504 - val_loss: 1.8443 - val_mae: 1.8319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d05101c580>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelN = tuner.hypermodel.build(best_hps)\n",
    "modelN.fit(X_train, y_train, epochs=25, batch_size=192,validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 2.0870 - mae: 2.0811 - val_loss: 1.8502 - val_mae: 1.8439\n",
      "Epoch 2/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.9040 - mae: 1.8976 - val_loss: 1.7982 - val_mae: 1.7915\n",
      "Epoch 3/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.8603 - mae: 1.8535 - val_loss: 1.7740 - val_mae: 1.7667\n",
      "Epoch 4/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.8549 - mae: 1.8475 - val_loss: 1.7869 - val_mae: 1.7792\n",
      "Epoch 5/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.7789 - mae: 1.7712 - val_loss: 1.7939 - val_mae: 1.7858\n",
      "Epoch 6/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.7762 - mae: 1.7680 - val_loss: 1.8067 - val_mae: 1.7983\n",
      "Epoch 7/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.7637 - mae: 1.7552 - val_loss: 1.7782 - val_mae: 1.7692\n",
      "Epoch 8/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.7802 - mae: 1.7711 - val_loss: 1.8724 - val_mae: 1.8630\n",
      "Epoch 9/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.7818 - mae: 1.7723 - val_loss: 1.8779 - val_mae: 1.8680\n",
      "Epoch 10/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.7391 - mae: 1.7290 - val_loss: 1.8269 - val_mae: 1.8165\n",
      "Epoch 11/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.7309 - mae: 1.7204 - val_loss: 1.8013 - val_mae: 1.7904\n",
      "Epoch 12/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.7100 - mae: 1.6989 - val_loss: 1.8369 - val_mae: 1.8253\n",
      "Epoch 13/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.7196 - mae: 1.7078 - val_loss: 1.8044 - val_mae: 1.7922\n",
      "Epoch 14/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.7048 - mae: 1.6924 - val_loss: 1.8641 - val_mae: 1.8513\n",
      "Epoch 15/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.6797 - mae: 1.6668 - val_loss: 1.9224 - val_mae: 1.9090\n",
      "Epoch 16/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.6296 - mae: 1.6161 - val_loss: 1.8426 - val_mae: 1.8286\n",
      "Epoch 17/25\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 1.6128 - mae: 1.5987 - val_loss: 1.8556 - val_mae: 1.8411\n",
      "Epoch 18/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.6634 - mae: 1.6487 - val_loss: 1.8220 - val_mae: 1.8069\n",
      "Epoch 19/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.5972 - mae: 1.5819 - val_loss: 1.8280 - val_mae: 1.8123\n",
      "Epoch 20/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.5901 - mae: 1.5742 - val_loss: 1.8149 - val_mae: 1.7987\n",
      "Epoch 21/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.6174 - mae: 1.6010 - val_loss: 1.8475 - val_mae: 1.8307\n",
      "Epoch 22/25\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 1.6254 - mae: 1.6085 - val_loss: 1.9235 - val_mae: 1.9061\n",
      "Epoch 23/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.5979 - mae: 1.5803 - val_loss: 1.8921 - val_mae: 1.8739\n",
      "Epoch 24/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.5324 - mae: 1.5142 - val_loss: 1.9083 - val_mae: 1.8897\n",
      "Epoch 25/25\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 1.5715 - mae: 1.5528 - val_loss: 1.8683 - val_mae: 1.8491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d0592e9c10>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelS = sanityN()\n",
    "modelS.fit(X_train, y_train, epochs=25, batch_size=64,validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11072, 53)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 53)]              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 53)                2862      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 45)                2430      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 53)                2438      \n",
      "=================================================================\n",
      "Total params: 7,730\n",
      "Trainable params: 7,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "173/173 - 1s - loss: 0.7521 - val_loss: 0.3175\n",
      "Epoch 2/50\n",
      "173/173 - 0s - loss: 0.2145 - val_loss: 0.1636\n",
      "Epoch 3/50\n",
      "173/173 - 0s - loss: 0.1190 - val_loss: 0.0981\n",
      "Epoch 4/50\n",
      "173/173 - 0s - loss: 0.0718 - val_loss: 0.0593\n",
      "Epoch 5/50\n",
      "173/173 - 0s - loss: 0.0461 - val_loss: 0.0391\n",
      "Epoch 6/50\n",
      "173/173 - 0s - loss: 0.0315 - val_loss: 0.0277\n",
      "Epoch 7/50\n",
      "173/173 - 0s - loss: 0.0227 - val_loss: 0.0204\n",
      "Epoch 8/50\n",
      "173/173 - 0s - loss: 0.0170 - val_loss: 0.0156\n",
      "Epoch 9/50\n",
      "173/173 - 0s - loss: 0.0129 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "173/173 - 0s - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 11/50\n",
      "173/173 - 0s - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 12/50\n",
      "173/173 - 0s - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 13/50\n",
      "173/173 - 0s - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 14/50\n",
      "173/173 - 0s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 15/50\n",
      "173/173 - 0s - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 16/50\n",
      "173/173 - 0s - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 17/50\n",
      "173/173 - 0s - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      "173/173 - 0s - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 19/50\n",
      "173/173 - 0s - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "173/173 - 0s - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 21/50\n",
      "173/173 - 0s - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 22/50\n",
      "173/173 - 0s - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 23/50\n",
      "173/173 - 0s - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "173/173 - 0s - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 25/50\n",
      "173/173 - 0s - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 26/50\n",
      "173/173 - 0s - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 27/50\n",
      "173/173 - 0s - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 28/50\n",
      "173/173 - 0s - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 29/50\n",
      "173/173 - 0s - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 30/50\n",
      "173/173 - 0s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 31/50\n",
      "173/173 - 0s - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 32/50\n",
      "173/173 - 0s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "173/173 - 0s - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 34/50\n",
      "173/173 - 0s - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 35/50\n",
      "173/173 - 0s - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "173/173 - 0s - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 37/50\n",
      "173/173 - 0s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 38/50\n",
      "173/173 - 0s - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "173/173 - 0s - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "173/173 - 0s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 41/50\n",
      "173/173 - 0s - loss: 9.9420e-04 - val_loss: 0.0010\n",
      "Epoch 42/50\n",
      "173/173 - 0s - loss: 9.2890e-04 - val_loss: 0.0011\n",
      "Epoch 43/50\n",
      "173/173 - 0s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 44/50\n",
      "173/173 - 0s - loss: 9.8879e-04 - val_loss: 0.0013\n",
      "Epoch 45/50\n",
      "173/173 - 0s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "173/173 - 0s - loss: 8.8857e-04 - val_loss: 9.8990e-04\n",
      "Epoch 47/50\n",
      "173/173 - 0s - loss: 8.8539e-04 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "173/173 - 0s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 49/50\n",
      "173/173 - 0s - loss: 9.5463e-04 - val_loss: 9.7786e-04\n",
      "Epoch 50/50\n",
      "173/173 - 0s - loss: 8.5109e-04 - val_loss: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d0811d8c10>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = keras.Input(shape=(53,))\n",
    "encoded = l.Dense(53, activation='relu', activity_regularizer=keras.regularizers.l1_l2(None, None))(input_data)\n",
    "\n",
    "encoded = l.Dense(45)(encoded)\n",
    "\n",
    "decoded = l.Dense(53, activation='linear')(encoded)\n",
    "\n",
    "autoencoder = keras.Model(input_data, decoded)\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(optimizer=\"adam\", loss='mse')\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=64,\n",
    "                verbose = 2,\n",
    "                validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11072, 45) (2768, 45) (12065, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((11072, 45), (2768, 45), (12065, 45))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = keras.Model(inputs=input_data, outputs=encoded)\n",
    "Z = encoder.predict(X_train)\n",
    "Zt= encoder.predict(X_test)\n",
    "TT = encoder.predict(test)\n",
    "print(Z.shape, Zt.shape,  TT.shape)\n",
    "\"\"\"Z = np.hstack((Z,X_train[:,30:]))\n",
    "Zt = np.hstack((Zt,X_test[:,30:]))\n",
    "TT = np.hstack((TT, test[:,30:]))\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "N_INPUTS = Z.shape[1]\n",
    "Z.shape, Zt.shape,  TT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 440 Complete [00h 00m 04s]\n",
      "mae: 1.8160310983657837\n",
      "\n",
      "Best mae So Far: 1.6424278020858765\n",
      "Total elapsed time: 00h 26m 18s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = MyTuner(reg, objective = \"mae\", factor=5, hyperband_iterations=10, seed = 2137, max_epochs = 25,overwrite=True, project_name = 'NZ')\n",
    "tuner.search(Z, y_train, epochs = 20, validation_data = (Zt, y_test),callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\NZ\n",
      "Showing 10 best trials\n",
      "Objective(name='mae', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.0012312087346884608\n",
      "units_0: 160\n",
      "dense_activation_0: relu\n",
      "units_1: 144\n",
      "dense_activation_1: relu\n",
      "dropout_1: 0.25\n",
      "units_2: 160\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.0\n",
      "units_3: 112\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.0\n",
      "units_4: 64\n",
      "dense_activation_4: selu\n",
      "dropout_4: 0.25\n",
      "learning_rate: 0.0005511246797862368\n",
      "batch_size: 128\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 757e082aec37f15bc9fc62d4071f741b\n",
      "Score: 1.6424278020858765\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.0006136572307132355\n",
      "units_0: 96\n",
      "dense_activation_0: relu\n",
      "units_1: 160\n",
      "dense_activation_1: elu\n",
      "dropout_1: 0.35000000000000003\n",
      "units_2: 64\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.35000000000000003\n",
      "units_3: 80\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.1\n",
      "units_4: 112\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.35000000000000003\n",
      "learning_rate: 0.0025289532699025036\n",
      "batch_size: 192\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 1.6591978073120117\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.0009375337116720802\n",
      "units_0: 144\n",
      "dense_activation_0: relu\n",
      "units_1: 128\n",
      "dense_activation_1: relu\n",
      "dropout_1: 0.4\n",
      "units_2: 64\n",
      "dense_activation_2: elu\n",
      "dropout_2: 0.15000000000000002\n",
      "units_3: 160\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.25\n",
      "units_4: 32\n",
      "dense_activation_4: selu\n",
      "dropout_4: 0.0\n",
      "learning_rate: 0.00018942177895293755\n",
      "batch_size: 32\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 1.699188232421875\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.0001270527174815734\n",
      "units_0: 80\n",
      "dense_activation_0: relu\n",
      "units_1: 144\n",
      "dense_activation_1: relu\n",
      "dropout_1: 0.45\n",
      "units_2: 176\n",
      "dense_activation_2: selu\n",
      "dropout_2: 0.30000000000000004\n",
      "units_3: 128\n",
      "dense_activation_3: selu\n",
      "dropout_3: 0.25\n",
      "units_4: 48\n",
      "dense_activation_4: elu\n",
      "dropout_4: 0.05\n",
      "learning_rate: 0.0025359172395390105\n",
      "batch_size: 192\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 52cb3178f9930e7b2fac73de1af9429d\n",
      "Score: 1.7125771045684814\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 1.6987075836249223e-06\n",
      "units_0: 96\n",
      "dense_activation_0: relu\n",
      "units_1: 96\n",
      "dense_activation_1: relu\n",
      "dropout_1: 0.05\n",
      "units_2: 176\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.2\n",
      "units_3: 144\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.5\n",
      "units_4: 64\n",
      "dense_activation_4: elu\n",
      "dropout_4: 0.1\n",
      "learning_rate: 0.001649474290614598\n",
      "batch_size: 192\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0f008ec34a761d2d8548c2cf30e52207\n",
      "Score: 1.7364720106124878\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.0030302742343263755\n",
      "units_0: 80\n",
      "dense_activation_0: relu\n",
      "units_1: 80\n",
      "dense_activation_1: elu\n",
      "dropout_1: 0.35000000000000003\n",
      "units_2: 32\n",
      "dense_activation_2: elu\n",
      "dropout_2: 0.35000000000000003\n",
      "units_3: 96\n",
      "dense_activation_3: relu\n",
      "dropout_3: 0.5\n",
      "units_4: 48\n",
      "dense_activation_4: elu\n",
      "dropout_4: 0.1\n",
      "learning_rate: 0.0006564307435068998\n",
      "batch_size: 64\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 1.752223014831543\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.004612995290521153\n",
      "units_0: 144\n",
      "dense_activation_0: relu\n",
      "units_1: 32\n",
      "dense_activation_1: selu\n",
      "dropout_1: 0.1\n",
      "units_2: 128\n",
      "dense_activation_2: selu\n",
      "dropout_2: 0.0\n",
      "units_3: 144\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.35000000000000003\n",
      "units_4: 32\n",
      "dense_activation_4: relu\n",
      "dropout_4: 0.05\n",
      "learning_rate: 0.0004209841475278669\n",
      "batch_size: 96\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 4af0a0e762c89c142662305b529de87a\n",
      "Score: 1.7531627416610718\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.0007271896219547906\n",
      "units_0: 160\n",
      "dense_activation_0: selu\n",
      "units_1: 96\n",
      "dense_activation_1: elu\n",
      "dropout_1: 0.05\n",
      "units_2: 64\n",
      "dense_activation_2: relu\n",
      "dropout_2: 0.0\n",
      "units_3: 48\n",
      "dense_activation_3: selu\n",
      "dropout_3: 0.35000000000000003\n",
      "units_4: 112\n",
      "dense_activation_4: selu\n",
      "dropout_4: 0.30000000000000004\n",
      "learning_rate: 0.0003991514902036776\n",
      "batch_size: 32\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0606f42455c90ceff18620eb70c18b79\n",
      "Score: 1.7572901248931885\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 1.5426683707169144e-06\n",
      "units_0: 112\n",
      "dense_activation_0: relu\n",
      "units_1: 64\n",
      "dense_activation_1: elu\n",
      "dropout_1: 0.0\n",
      "units_2: 160\n",
      "dense_activation_2: elu\n",
      "dropout_2: 0.30000000000000004\n",
      "units_3: 32\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.30000000000000004\n",
      "units_4: 96\n",
      "dense_activation_4: elu\n",
      "dropout_4: 0.15000000000000002\n",
      "learning_rate: 0.0008979340534482525\n",
      "batch_size: 224\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: df54fddb959f451a23ba83c45e54e4d8\n",
      "Score: 1.7576234340667725\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "regularizers: 0.00021052560182251796\n",
      "units_0: 192\n",
      "dense_activation_0: relu\n",
      "units_1: 144\n",
      "dense_activation_1: selu\n",
      "dropout_1: 0.2\n",
      "units_2: 48\n",
      "dense_activation_2: elu\n",
      "dropout_2: 0.1\n",
      "units_3: 128\n",
      "dense_activation_3: elu\n",
      "dropout_3: 0.2\n",
      "units_4: 128\n",
      "dense_activation_4: elu\n",
      "dropout_4: 0.05\n",
      "learning_rate: 0.005285473834357042\n",
      "batch_size: 64\n",
      "tuner/epochs: 25\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 43ca8069c801d1c4c120b83056c67527\n",
      "Score: 1.7611727714538574\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "modelN = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 160)               7360      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 144)               23184     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 160)               23200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 112)               18032     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                7232      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 79,073\n",
      "Trainable params: 79,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.7161 - mae: 1.5323 - val_loss: 2.1407 - val_mae: 1.9581\n",
      "Epoch 2/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.7047 - mae: 1.5208 - val_loss: 2.2230 - val_mae: 2.0383\n",
      "Epoch 3/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.6518 - mae: 1.4667 - val_loss: 2.0801 - val_mae: 1.8951\n",
      "Epoch 4/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.6307 - mae: 1.4455 - val_loss: 2.0710 - val_mae: 1.8849\n",
      "Epoch 5/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.6054 - mae: 1.4193 - val_loss: 2.1344 - val_mae: 1.9477\n",
      "Epoch 6/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5936 - mae: 1.4072 - val_loss: 2.1482 - val_mae: 1.9617\n",
      "Epoch 7/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5828 - mae: 1.3957 - val_loss: 2.0470 - val_mae: 1.8592\n",
      "Epoch 8/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5700 - mae: 1.3812 - val_loss: 2.0860 - val_mae: 1.8971\n",
      "Epoch 9/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5695 - mae: 1.3808 - val_loss: 2.2252 - val_mae: 2.0342\n",
      "Epoch 10/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5582 - mae: 1.3680 - val_loss: 2.1403 - val_mae: 1.9491\n",
      "Epoch 11/25\n",
      "346/346 [==============================] - 2s 4ms/step - loss: 1.5337 - mae: 1.3427 - val_loss: 2.2016 - val_mae: 2.0097\n",
      "Epoch 12/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5412 - mae: 1.3501 - val_loss: 2.1741 - val_mae: 1.9817\n",
      "Epoch 13/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5302 - mae: 1.3378 - val_loss: 2.0741 - val_mae: 1.8824\n",
      "Epoch 14/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5139 - mae: 1.3221 - val_loss: 2.1198 - val_mae: 1.9276\n",
      "Epoch 15/25\n",
      "346/346 [==============================] - 1s 4ms/step - loss: 1.5111 - mae: 1.3182 - val_loss: 2.1198 - val_mae: 1.9265\n",
      "Epoch 16/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5110 - mae: 1.3174 - val_loss: 2.0731 - val_mae: 1.8804\n",
      "Epoch 17/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.5021 - mae: 1.3084 - val_loss: 2.0675 - val_mae: 1.8724\n",
      "Epoch 18/25\n",
      "346/346 [==============================] - 2s 4ms/step - loss: 1.4816 - mae: 1.2868 - val_loss: 2.0809 - val_mae: 1.8845\n",
      "Epoch 19/25\n",
      "346/346 [==============================] - 1s 4ms/step - loss: 1.4980 - mae: 1.3021 - val_loss: 2.1456 - val_mae: 1.9496\n",
      "Epoch 20/25\n",
      "346/346 [==============================] - 2s 4ms/step - loss: 1.4792 - mae: 1.2830 - val_loss: 2.1887 - val_mae: 1.9908\n",
      "Epoch 21/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.4786 - mae: 1.2810 - val_loss: 2.1064 - val_mae: 1.9097\n",
      "Epoch 22/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.4604 - mae: 1.2639 - val_loss: 2.1810 - val_mae: 1.9836\n",
      "Epoch 23/25\n",
      "346/346 [==============================] - 2s 5ms/step - loss: 1.4681 - mae: 1.2706 - val_loss: 2.0943 - val_mae: 1.8971\n",
      "Epoch 24/25\n",
      "346/346 [==============================] - 2s 4ms/step - loss: 1.4673 - mae: 1.2693 - val_loss: 2.1793 - val_mae: 1.9805\n",
      "Epoch 25/25\n",
      "346/346 [==============================] - 1s 4ms/step - loss: 1.4627 - mae: 1.2636 - val_loss: 2.1493 - val_mae: 1.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d0561115b0>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelN.fit(Z, y_train, epochs=25, batch_size=32,validation_data = (Zt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 2ms/step - loss: 2.0006 - mae: 1.7668\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "loss, mae = best_model.evaluate(Zt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kerastuner.engine.hyperparameters.HyperParameters at 0x1d0513ae730>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       ...,\n",
       "       [0.07745825],\n",
       "       [0.        ],\n",
       "       [0.06240635]], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(modelN.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.194045222096198"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predN =(modelN.predict(X_test)) \n",
    "mean_absolute_error(y_test, predN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testL = np.log(y_test)\n",
    "y_trainL = np.log(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = MyTuner(reg, objective = \"mae\", factor=2, hyperband_iterations=10, seed = 2137, max_epochs = 50,overwrite=True, project_name = 'L')\n",
    "tuner.search(X_train, y_trainL, epochs = 20, validation_data = (X_test, y_testL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8522134],\n",
       "       [3.9126532],\n",
       "       [4.0459185],\n",
       "       ...,\n",
       "       [2.9359365],\n",
       "       [3.0215716],\n",
       "       [4.7637897]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(modelL.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNfqrlRTtawi",
    "outputId": "94a534f9-22ab-4aad-b367-76ba4c7f8010"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7611305438180407"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predL =np.exp(modelL.predict(X_test))\n",
    "mean_absolute_error(y_test, predL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8132667828145463 1.9562198088838099\n",
      "1.8459928547736852\n",
      "0.9507200397338081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 5.0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predL_test =np.exp(modelL.predict(X_train))\n",
    "predN_test =(modelN.predict(X_train))\n",
    "print(mean_absolute_error(y_train, predL_test), mean_absolute_error(y_train, predN_test))\n",
    "\n",
    "preD_test = np.array(((predN_test+predL_test)/2)-0.3)\n",
    "preDlim_test = preD_test\n",
    "predLlim_test = predL_test\n",
    "pred_test= np.array([1*x*np.log(x+1) if x <1.5 else (y-0.3) for x,y in zip(preDlim_test, predLlim_test)])\n",
    "print(mean_absolute_error(y_train, pred_test))\n",
    "print(mean_absolute_error(y_train[y_train<5], pred_test[y_train<5]))\n",
    "plt.hist([pred_test.reshape(11072     ,),y_train], 1000)\n",
    "plt.xlim(0,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7611305438180407 1.8599237800939752\n",
      "1.7903252185039773\n",
      "0.9509920774285221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 5.0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predL_test =np.exp(modelL.predict(X_test))\n",
    "predN_test =(modelN.predict(X_test))\n",
    "print(mean_absolute_error(y_test, predL_test), mean_absolute_error(y_test, predN_test))\n",
    "\n",
    "preD_test = np.array(((predN_test+predL_test)/2)-0.3)\n",
    "preDlim_test = preD_test\n",
    "predLlim_test = predL_test\n",
    "pred_test= np.array([1*x*np.log(x+1) if x <1.5 else (y-0.3) for x,y in zip(preDlim_test, predLlim_test)])\n",
    "print(mean_absolute_error(y_test, pred_test))\n",
    "print(mean_absolute_error(y_test[y_test<5], pred_test[y_test<5]))\n",
    "plt.hist([pred_test.reshape(2768    ,),y_test], 1000)\n",
    "plt.xlim(0,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVkzutmHO0k4",
    "outputId": "b7883eae-56fb-4ea6-a21d-7bca05267011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2951956, 2.7939818)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissionL =np.exp(modelL.predict(test))\n",
    "submissionN =(modelN.predict(test))\n",
    "finaL = np.array(((submissionN+submissionL)/2)-0.3)\n",
    "very_nice = np.array([1*x*np.log(x+1) if x <1.5 else (y-0.3) for x,y in zip(finaL, submissionL)])\n",
    "np.mean(very_nice), np.var(very_nice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 10.0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.hist(very_nice,bins = 1000)\n",
    "plt.xlim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "VA4SBvOcpErC"
   },
   "outputs": [],
   "source": [
    "def submit(prediction, name):\n",
    "    my_submission = submission_csv \n",
    "    my_submission[\"LOS\"] =  prediction\n",
    "    my_submission = my_submission.sort_values('icustay_id')\n",
    "    my_submission.to_csv(name, index=False)\n",
    "submit(very_nice, \"very_nice_and_simple.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of piotr_antoniak_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
